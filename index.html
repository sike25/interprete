<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="index.css">
    <title>Interpretability of Deep Neural Networks, Spring 2025</title>
</head>
<body>
    <header>
        <h1>Interpretability of Deep Neural Networks, Spring 2025</h1>
        <h2>Osasikemwen Ogieva, supervised by Dr. Andrew (Haoze) Wu</h2>
    </header>
    
    <main>
        <ul>
            
            <!-- what is interpretability? -->
            <li>
                <a href="intro/lipton.html" class="paper-link">Lipton, Mythos of Model Interpretability (2016)</a>
            </li>
            <!-- <li>
                <a href="intro/doshi.html" class="paper-link">Doshi-Velez, Kim, Towards A Rigorous Science of Interpretable Machine Learning (2017)</a>
            </li>
            <li>
                <a href="intro/ross.html" class="paper-link">Ross, Right for the Right Reasons (2017)</a>
            </li> -->



            <!-- saliency -->
            <li>
                <a href="saliency/cam.html" class="paper-link">Zhou: CAM: Learning Deep Features for Discriminative Localization (2015)</a>
            </li>
            <li>
                <a href="saliency/smoothgrad.html" class="paper-link">Smilkov, SmoothGrad: Removing Noise by Adding Noise (2017)</a>
            </li>
            <!-- <li>
                <a href="saliency/li.html" class="paper-link">Li, Visualizing and Understanding Neural Models in NLP (2016)</a>
            </li>
            <li>
                <a href="saliency/ding.html" class="paper-link">Ding, Saliency-driven Word Alignment Interpretation for Neural Machine Translation (2019)</a>
            </li> -->
            <li>
                <a href="saliency/mudrakarta.html" class="paper-link">Mudrakarta, Did the Model Understand the Question? (2018)</a>
            </li>




            <!-- explaining models -->
            <li>
                <a href="models/belinkov.html" class="paper-link">Belinkov, Analysis Methods in Neural Language Processing (2019)</a>
            </li>
            <li>
                <a href="models/netdissect.html" class="paper-link">Bau, Network Dissection: Quantifying Interpretability of Deep Visual Representations (2017)</a>
            </li>
            <!-- <li>
                <a href="models/gandissect.html" class="paper-link">Bau, GAN Dissection: Visualizing and Understanding Generative Adversarial Networks (2018)</a>
            </li> -->



            <!-- adversaries -->
            <li>
                <a href="adversarial/goodfellow.html" class="paper-link">Goodfellow, Explaining and Harnessing Adversarial Examples (2015)</a>
            </li>



            <!-- bias  -->
            <li>
                <a href="bias/gendershades.html" class="paper-link">Buolamwini, Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification</a>
            </li>
            <li>
                <a href="bias/chouldechova.html" class="paper-link">Chouldechova, Fair Prediction with Disparate Impact: A study of bias in recidivism prediction instruments</a>
            </li>
            <li>
                <a href="bias/ziad.html" class="paper-link">Ziad, Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations</a>
            </li>




             <!-- interaction  -->
            <li>
                <a href="interaction/seqtoseq.html" class="paper-link">Strobelt, SEQ2SEQ-VIS : A Visual Debugging Tool for Sequence-to-Sequence Models (2018)</a>
            </li>
            <li>
                <a href="interaction/andreas.html" class="paper-link">Andreas, Analogs of Linguistic Structure in Deep Representations (2017)</a>
            </li>
            <!-- <li>
                <a href="interaction/gehrmann.html" class="paper-link">Gehrmann, Visual Interaction with Deep Learning Methods (2019)</a>
            </li>
            <li>
                <a href="interaction/hendricksgen.html" class="paper-link">Hendricks, Generating Visual Explanations (2016)</a>
            </li>
            <li>
                <a href="interaction/hendricksground.html" class="paper-link">Hendricks, Grounding Visual Explanations (2018)</a>
            </li> -->


            
             <!-- more topics  -->
             <li>
                <a href="extra/kan.html" class="paper-link">Liu, Kolmogorov-Arnold Networks (2024)</a>
            </li>
            <li>
                <a href="extra/neurosymbolic.html" class="paper-link">Neurosymbolic Methods</a>
            </li>
        </ul>
    </main>
    
    <footer>
        <p>Â© 2025 Sike Ogieva | Last updated: May 2025</p>
    </footer>

    <script>
        // You can add JavaScript functionality here if needed
        document.addEventListener('DOMContentLoaded', function() {
            console.log('Page loaded successfully');
        });
    </script>
</body>
</html>